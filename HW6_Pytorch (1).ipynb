{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Финальный результат:** test accuracy 0.994 <br>\n",
        "Чем больше берём слов в max_words, тем лучше результат.\n",
        "\n",
        "max_len достаточно и 10. Эпох тоже\n",
        "\n",
        "Dropout в модели не сильно влияет. Возможно влияет кол-во слоев\n",
        "\n",
        "Подозреваю, что не сложный датасет, поэтому результаты хорошие, даже простая самописная нейронка справляется"
      ],
      "metadata": {
        "id": "tO4ZY3lBOVt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "YpzUCYeO7Owu"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "ySV58seEyjGX"
      },
      "outputs": [],
      "source": [
        "max_words = 4000\n",
        "max_len = 10\n",
        "num_classes = 1\n",
        "\n",
        "# Training\n",
        "epochs = 10\n",
        "batch_size = 512\n",
        "print_batch_n = 100\n",
        "\n",
        "th = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "final_test = pd.read_csv(\"test.csv\")\n"
      ],
      "metadata": {
        "id": "hhMapGHj0t90"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_train['tweet'], df_train['label'], test_size=0.25, random_state=26)"
      ],
      "metadata": {
        "id": "XsXQ-YD77V-d"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqVODhed0_jD",
        "outputId": "0afe9280-c912-4a26-82a2-958fad321f51"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10549    @user so sweet. .  fathers day ..love u devð...\n",
              "24767                              porn vids web free sex \n",
              "13400    @user chicken breast with homemade bbq sauce, ...\n",
              "25055    i am thankful for comfo. #thankful #positive     \n",
              "15595    quick scan board for empathy now up on pintere...\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe__BXUL1Bfa",
        "outputId": "c37ca7e2-6783-4db7-c8cc-27405cf24214"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22757    visiting a friend and finding your book in the...\n",
              "7670     can't help #smiling when i #color this!   #sat...\n",
              "16618    saving a #year with a single #drive  #fun #fri...\n",
              "11168    #winterfashion   bull up: you will dominate yo...\n",
              "11138                    gonna be doing new content soon  \n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stop_words pymorphy2"
      ],
      "metadata": {
        "id": "x-AeJxTY4LO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d0ca74-98d1-4f7b-d3ba-8a88584fb986"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stop_words in /usr/local/lib/python3.10/dist-packages (2018.7.23)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.10/dist-packages (0.9.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import re"
      ],
      "metadata": {
        "id": "sqKoybzt1H7H"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sw = set(get_stop_words(\"en\"))\n",
        "exclude = set(punctuation)\n",
        "morpher = MorphAnalyzer()\n",
        "\n",
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in exclude)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(\"\\snot\", \"not\", txt)\n",
        "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
        "    return \" \".join(txt)\n",
        "\n",
        "X_train = X_train.apply(preprocess_text)\n",
        "X_test = X_test.apply(preprocess_text)"
      ],
      "metadata": {
        "id": "12JHh9yC1h9Y"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0sWqlOz15Ut",
        "outputId": "94c14f07-008b-4507-c074-5b9ea4b7e614"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10549    user sweet fathers day love u devðððð...\n",
              "24767                               porn vids web free sex\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus = \" \".join(X_train)\n",
        "train_corpus = train_corpus.lower()"
      ],
      "metadata": {
        "id": "4yQdPyKs2Dyz"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "tokens = word_tokenize(train_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVqAn-ye2L5j",
        "outputId": "d5882c91-e106-4e09-dba4-e1ae4bad392d"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_filtered = [word for word in tokens if word.isalnum()]"
      ],
      "metadata": {
        "id": "fGkSkUP22W-l"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "dist = FreqDist(tokens_filtered)\n",
        "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
      ],
      "metadata": {
        "id": "esqZr0j_2eyE"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_filtered_top[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1drrQGnE2pCK",
        "outputId": "429f1ee2-fd5f-4f6f-f9ce-673fba88c61b"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['user', 'love', 'day', 'happy', 'amp', 'just', 'will', 'u', 'time', 'im']"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
      ],
      "metadata": {
        "id": "XmNpKB3Y2_fV"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def text_to_sequence(text, maxlen):\n",
        "    result = []\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
        "    for word in tokens_filtered:\n",
        "        if word in vocabulary:\n",
        "            result.append(vocabulary[word])\n",
        "    padding = [0]*(maxlen-len(result))\n",
        "    return padding + result[-maxlen:]"
      ],
      "metadata": {
        "id": "iXlHL6m83Mnz"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.asarray([text_to_sequence(text, max_len) for text in X_train], dtype=np.int32)\n",
        "x_test = np.asarray([text_to_sequence(text, max_len) for text in X_test], dtype=np.int32)"
      ],
      "metadata": {
        "id": "bSYtlfoo3XcF"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[12345]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ibu58q3v3XnA",
        "outputId": "ec0a9ebf-1a1e-44a8-d3b4-76607727e418"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0, 3678, 3965,  338,   25,  122,  750, 2158, 1954],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "YsFlkWqB4hEr",
        "outputId": "5d3eae67-a3d0-45a3-bf12-11b0a22e29e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23971, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "seed = 26\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "QwB8Xfde4Xtg"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, vocab_size=20, embedding_dim = 128, out_channel = 128, num_classes = 1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.dp = nn.Dropout(0.25)\n",
        "        self.conv_1 = nn.Conv1d(embedding_dim, out_channel, kernel_size=2)\n",
        "        self.conv_2 = nn.Conv1d(embedding_dim, out_channel, kernel_size=3)\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear1 = nn.Linear(out_channel, out_channel//2)\n",
        "        self.linear2 = nn.Linear(out_channel//2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.embedding(x)\n",
        "        #                       B  F  L\n",
        "        output = output.permute(0, 2, 1)\n",
        "        output = self.dp(output)\n",
        "        output = self.conv_1(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.pool(output)\n",
        "        output = self.conv_2(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.pool(output)\n",
        "        output = torch.max(output, axis=2).values\n",
        "        output = self.linear1(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.linear2(output)\n",
        "        output = F.sigmoid(output)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "d0Zd5y034b5Y"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class DataWrapper(Dataset):\n",
        "    def __init__(self, data, target=None, transform=None):\n",
        "        self.data = torch.from_numpy(data).long()\n",
        "        if target is not None:\n",
        "            self.target = torch.from_numpy(target).long()\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index] if self.target is not None else None\n",
        "\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "om2JKsFf6ee1"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device\n"
      ],
      "metadata": {
        "id": "L9KGOTiL9F_p",
        "outputId": "fb8ddec3-3c24-483e-b942-b1244ba0ff31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net(vocab_size=max_words).to(device)\n",
        "\n",
        "print(model)\n",
        "print(\"Parameters:\", sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "model.train()\n",
        "#model = model.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=10e-3)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "\n",
        "train_dataset = DataWrapper(x_train, y_train.values)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = DataWrapper(x_test, y_test.values)\n",
        "test_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "hHBJlOaO6jIx",
        "outputId": "b511fa68-cbe8-4a7b-c8b0-0dd7e8753e08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (embedding): Embedding(4000, 128)\n",
            "  (dp): Dropout(p=0.25, inplace=False)\n",
            "  (conv_1): Conv1d(128, 128, kernel_size=(2,), stride=(1,))\n",
            "  (conv_2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
            "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (relu): ReLU()\n",
            "  (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (linear2): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n",
            "Parameters: 602497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "manual_acc = []\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    model.train()\n",
        "    right, num = 0, 0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels.float().view(-1,1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        right += (labels == torch.squeeze((outputs > th).int())).sum()\n",
        "        num += len(labels)\n",
        "\n",
        "    model.eval()\n",
        "    loss_accumed, test_right, test_num = 0, 0, 0\n",
        "    for i, data in enumerate(test_loader, 0):\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        output = model(X)\n",
        "        loss = criterion(output, y.float().view(-1,1))\n",
        "        loss_accumed += loss\n",
        "        test_num += len(y)\n",
        "        test_right += (y == torch.squeeze((output > th).int())).sum()\n",
        "\n",
        "    train_acc = right/num\n",
        "    test_acc = test_right/test_num\n",
        "    manual_acc.append(test_acc)\n",
        "    print(f\"Epoch {epoch+1}; test_loss {loss_accumed:.3f}; test_acc {test_acc:.3f}; train_acc {train_acc:.3f}\")\n",
        "\n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "id": "vd2MhfYr93RL",
        "outputId": "08dd2e33-d7fc-48c1-8eff-45c9d5577f9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [00:00<00:08,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1; test_loss 8.173; test_acc 0.929; train_acc 0.911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:02<00:11,  1.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2; test_loss 5.966; test_acc 0.951; train_acc 0.933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:03<00:08,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3; test_loss 4.467; test_acc 0.969; train_acc 0.954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:04<00:06,  1.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4; test_loss 3.296; test_acc 0.977; train_acc 0.964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [00:05<00:05,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5; test_loss 2.614; test_acc 0.981; train_acc 0.971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [00:06<00:04,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6; test_loss 2.534; test_acc 0.987; train_acc 0.978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [00:07<00:03,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7; test_loss 1.606; test_acc 0.989; train_acc 0.981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [00:08<00:02,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8; test_loss 1.235; test_acc 0.992; train_acc 0.984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [00:10<00:01,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9; test_loss 1.264; test_acc 0.994; train_acc 0.987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:11<00:00,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10; test_loss 0.956; test_acc 0.994; train_acc 0.988\n",
            "Training is finished!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}