{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Initial Test Accuracy:** 94,5%<br>\n",
        "**Final Test Accuracy:** 99,5%<br>\n",
        "**Adjustments:**<br>\n",
        "*   max_words = 400 -> 4000\n",
        "*   max_len = 5 -> 10\n",
        "*   Dropout added\n",
        "*   Learning Rate = 0.001 -> 0.01"
      ],
      "metadata": {
        "id": "K7DxzpJ4LQ9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install stop_words pymorphy2"
      ],
      "metadata": {
        "id": "gF2O8B02IWMN"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "0VigPOowFEMn"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import re\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-dJBlcjFJHPX",
        "outputId": "e5cff7ac-23f2-4db8-a377-04400a96ab85"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 4000\n",
        "max_len = 10\n",
        "num_classes = 1\n",
        "\n",
        "# Training\n",
        "epochs = 10\n",
        "batch_size = 512\n",
        "print_batch_n = 100\n",
        "\n",
        "th = 0.5"
      ],
      "metadata": {
        "id": "sksOdIv0IJ_q"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "final_test = pd.read_csv(\"test.csv\")\n"
      ],
      "metadata": {
        "id": "Rx1inAQ0IMuY"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_train['tweet'], df_train['label'], test_size=0.25, random_state=26)"
      ],
      "metadata": {
        "id": "NQBMvOFLIOyO"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7CUQ835IRE0",
        "outputId": "5334c3f5-b407-4cc9-f53a-bd96fb446ffa"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10549    @user so sweet. .  fathers day ..love u devð...\n",
              "24767                              porn vids web free sex \n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9lITda9IRrC",
        "outputId": "4a132961-91e3-4a31-9f62-6ab0828572b9"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22757    visiting a friend and finding your book in the...\n",
              "7670     can't help #smiling when i #color this!   #sat...\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sw = set(get_stop_words(\"en\"))\n",
        "exclude = set(punctuation)\n",
        "morpher = MorphAnalyzer()\n",
        "\n",
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in exclude)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(\"\\snot\", \"not\", txt)\n",
        "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
        "    return \" \".join(txt)\n",
        "\n",
        "X_train = X_train.apply(preprocess_text)\n",
        "X_test = X_test.apply(preprocess_text)"
      ],
      "metadata": {
        "id": "hGJG2g-hISHP"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rMt4p2hISJm",
        "outputId": "9aa8ec0f-1288-4d1c-929f-ccc94c4ad8ad"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10549    user sweet fathers day love u devðððð...\n",
              "24767                               porn vids web free sex\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus = \" \".join(X_train)\n",
        "train_corpus = train_corpus.lower()"
      ],
      "metadata": {
        "id": "VpirvGt2Ig61"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "tokens = word_tokenize(train_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mndw-1LfIg9Y",
        "outputId": "fef34759-7d25-4f1a-f2ac-830f10e92f20"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_filtered = [word for word in tokens if word.isalnum()]"
      ],
      "metadata": {
        "id": "_AyrnE03IhA2"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "dist = FreqDist(tokens_filtered)\n",
        "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
      ],
      "metadata": {
        "id": "LauzegkmISNG"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_filtered_top[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7Bfb-WEIojI",
        "outputId": "a27f4b9b-26bd-4def-fefa-705e844f4538"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['user', 'love', 'day', 'happy', 'amp', 'just', 'will', 'u', 'time', 'im']"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
      ],
      "metadata": {
        "id": "1r9NcltEIolw"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_sequence(text, maxlen):\n",
        "    result = []\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
        "    for word in tokens_filtered:\n",
        "        if word in vocabulary:\n",
        "            result.append(vocabulary[word])\n",
        "    padding = [0]*(maxlen-len(result))\n",
        "    return padding + result[-maxlen:]"
      ],
      "metadata": {
        "id": "z78wTK-TIopW"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.asarray([text_to_sequence(text, max_len) for text in X_train], dtype=np.int32)\n",
        "x_test = np.asarray([text_to_sequence(text, max_len) for text in X_test], dtype=np.int32)"
      ],
      "metadata": {
        "id": "WQjWopP2Iy5w"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[12345]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LxdMg4cIy8a",
        "outputId": "60a9d71a-25b2-4e82-c322-d41cd7db4a2b"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0, 3678, 3965,  338,   25,  122,  750, 2158, 1954],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 26\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "ihOLPHlgIy__"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class DataWrapper(Dataset):\n",
        "    def __init__(self, data, target=None, transform=None):\n",
        "        self.data = torch.from_numpy(data).long()\n",
        "        if target is not None:\n",
        "            self.target = torch.from_numpy(target).long()\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index] if self.target is not None else None\n",
        "\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "YjqGArx6JBUN"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUFixedLen(nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, use_last=True) :\n",
        "        super().__init__()\n",
        "        self.use_last = use_last\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        gru_out, ht = self.gru(x)\n",
        "\n",
        "        if self.use_last:\n",
        "          last_tensor = gru_out[:,-1,:]\n",
        "        else:\n",
        "          last_tensor = torch.mean(gru_out[:,:], dim=1)\n",
        "\n",
        "        out = self.linear(last_tensor)\n",
        "        return torch.sigmoid(out)\n"
      ],
      "metadata": {
        "id": "tNOoJRdgGLtq"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_init = GRUFixedLen(max_words, 128, 20, use_last=True).to(device)\n",
        "optimizer = torch.optim.Adam(gru_init.parameters(), lr=0.01)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "print(gru_init)\n",
        "print(\"Parameters:\", sum([param.nelement() for param in gru_init.parameters()]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aJ9JDQHHqbw",
        "outputId": "a82dfb91-7ef3-407f-e54e-204ea39e18e3"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRUFixedLen(\n",
            "  (embeddings): Embedding(4000, 128, padding_idx=0)\n",
            "  (gru): GRU(128, 20, num_layers=2, batch_first=True)\n",
            "  (linear): Linear(in_features=20, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "Parameters: 523541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_init.train()\n",
        "#model = model.cuda()\n",
        "\n",
        "train_dataset = DataWrapper(x_train, y_train.values)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = DataWrapper(x_test, y_test.values)\n",
        "test_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "6BUECiOvJeji"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "manual_acc = []\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    gru_init.train()\n",
        "    right, num = 0, 0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = gru_init(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels.float().view(-1,1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        right += (labels == torch.squeeze((outputs > th).int())).sum()\n",
        "        num += len(labels)\n",
        "\n",
        "    gru_init.eval()\n",
        "    loss_accumed, test_right, test_num = 0, 0, 0\n",
        "    for i, data in enumerate(test_loader, 0):\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        output = gru_init(X)\n",
        "        loss = criterion(output, y.float().view(-1,1))\n",
        "        loss_accumed += loss\n",
        "        test_num += len(y)\n",
        "        test_right += (y == torch.squeeze((output > th).int())).sum()\n",
        "\n",
        "    train_acc = right/num\n",
        "    test_acc = test_right/test_num\n",
        "    manual_acc.append(test_acc)\n",
        "    print(f\"Epoch {epoch+1}; test_loss {loss_accumed:.3f}; test_acc {test_acc:.3f}; train_acc {train_acc:.3f}\")\n",
        "\n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1f5gcrMJ8Yp",
        "outputId": "b630034a-0852-42f0-acb9-0063784f9970"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [00:00<00:04,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1; test_loss 7.577; test_acc 0.950; train_acc 0.932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:01<00:04,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2; test_loss 4.666; test_acc 0.969; train_acc 0.955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:01<00:03,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3; test_loss 3.331; test_acc 0.979; train_acc 0.967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:02<00:03,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4; test_loss 2.477; test_acc 0.983; train_acc 0.974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [00:02<00:02,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5; test_loss 1.903; test_acc 0.988; train_acc 0.977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [00:03<00:02,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6; test_loss 1.474; test_acc 0.990; train_acc 0.981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [00:03<00:01,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7; test_loss 1.168; test_acc 0.993; train_acc 0.984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [00:04<00:01,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8; test_loss 0.872; test_acc 0.994; train_acc 0.986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [00:04<00:00,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9; test_loss 0.765; test_acc 0.995; train_acc 0.988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:05<00:00,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10; test_loss 0.702; test_acc 0.995; train_acc 0.989\n",
            "Training is finished!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}